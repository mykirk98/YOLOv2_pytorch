# anchors = [[0.57273, 0.677385], [1.87446, 2.06253], [3.33843, 5.47434], [7.88282, 3.52778], [9.77052, 9.16828]] ## Darknet COCO anchors
# anchors = [[1.3221, 1.73145], [3.19275, 4.00944], [5.05587, 8.09892], [9.47112, 4.84053], [11.2364, 10.0071]]
# anchors = [[1.08,1.19], [3.42,4.41], [6.63,11.38], [9.42,5.11], [16.62,10.52]]#darknet voc # I was using these anchors
# anchors = [[0.15, 0.22], [0.39, 0.60], [0.96, 1.1], [1.87, 2.11], [3.39,4.45]] # Waymo anchors
# anchors = [[0.2351108, 0.331236], [0.6067978, 0.9197248], [1.4826158, 1.6816062], [2.8759434, 3.2476076], [5.2168172, 6.8450474]] # for waymo for 640x640
# anchors = [[0.2196817, 0.38881638], [0.53908652, 0.91577207], [1.19775591, 1.65588859], [2.24054113, 3.10920645], [3.92205269, 5.89715882]] # BDD validation anchors 
# anchors = [[0.32107321, 0.56827005], [0.78789561, 1.33843619], [1.75056633, 2.42014495], [3.27463708, 4.54422487], [5.73223084, 8.6189244]] # BDD for 608 x 608 --. 7.99mAp, from scratch 
# anchors = [0.57273, 0.677385], [1.87446, 2.06253], [3.33843, 5.47434], [7.88282, 3.52778], [9.77052, 9.16828]
# anchors = [[1.3221, 1.73145], [3.19275, 4.00944], [5.05587, 8.09892], [9.47112, 4.84053], [11.2364, 10.0071]]
# anchors = [[1.08,1.19], [3.42,4.41], [6.63,11.38], [9.42,5.11], [16.62,10.52]]
# anchors = [[0.15, 0.22], [0.39, 0.60], [0.96, 1.1], [1.87, 2.11], [3.39,4.45]]
# anchors = [[0.34,0.60], [0.83,1.41], [1.85,2.55], [3.45,4.78], [6.03,9.07]]     # BDD
anchors = [[0.33797184, 0.59817904], [0.82936387, 1.40888011], [1.84270141, 2.54752091], [3.44698635, 4.78339454], [6.03392721, 9.07255202]]        # BDD 640 --from Ali

object_scale = 5
noobject_scale = 1
class_scale = 1
coord_scale = 1

saturation = 1.5
exposure = 1.5
hue = .1

jitter = 0.3

thresh = .6

batch_size = 64

lr = 0.001

decay_lrs = {
    60: 0.00001,
    90: 0.000001,
}

momentum = 0.9
weight_decay = 0.00005


# multi-scale training:
# {k: epoch, v: scale range}
multi_scale = True

# number of steps to change input size
scale_step = 40

scale_range = (3, 4)

epoch_scale = {
    1:  (3, 4),
    15: (2, 5),
    30: (1, 6),
    60: (0, 7),
    75: (0, 9)
}

input_sizes = [
               (384, 384),
               (416, 416),
               (480, 480),
               (512, 512),
               (576, 576),
               (608, 608),
               (640, 640),]
# input_size = (416, 416)

# test_input_size = (416, 416)

input_size = (640, 640)  # 640 and 640 for 100 epochs 
                         # 672 and 672 for 100 epochs
                         # 704 and 704 for 100 epochs
                         # 736 and 736 fors 100 epochs
                         # Remove small objects from labels 
test_input_size = (640, 640)


strides = 32

debug = False        # it should have to return to 'False'

